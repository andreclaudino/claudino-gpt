vocabulary_size = 152064
context_legth = 128
embedding_dimension = 768
number_of_attention_heads = 12
number_of_transformer_blocks = 12
dropout_rate = 0.1
use_qkv_bias = false

embedding_multiplier_factor = 4